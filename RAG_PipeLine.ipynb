{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_docling import DoclingLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f414a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourece = \"ReAct.pdf\"\n",
    "loader = DoclingLoader(\n",
    "    file_path=sourece,\n",
    "    export_type = \"markdown\"\n",
    ")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f47147",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[0].page_content[:500])  # Print the first 500 characters of the first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Docling ë§ˆí¬ë‹¤ìš´ ì¶œë ¥ìš© ì„¹ì…˜ ë‹¨ìœ„ ë¶„í• \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # ì²­í¬ ìµœëŒ€ í¬ê¸°: 1200ì\n",
    "    # - ì˜ì–´ ë…¼ë¬¸ 1200ì â‰ˆ 300í† í° (ëŒ€ë¶€ë¶„ ì„ë² ë”© ëª¨ë¸ 512í† í° ì œí•œ ë‚´)\n",
    "    # - ë…¼ë¬¸ ì„¹ì…˜(Abstract, Introduction) ì „ì²´ë¥¼ í•œ ì²­í¬ë¡œ ìœ ì§€ ê°€ëŠ¥\n",
    "    # - ë„ˆë¬´ ì‘ìœ¼ë©´ ë¬¸ë§¥ ì†ì‹¤, ë„ˆë¬´ í¬ë©´ ê²€ìƒ‰ ì •í™•ë„ í•˜ë½\n",
    "    chunk_size=1200,\n",
    "    \n",
    "    # ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¶€ë¶„: 200ì (chunk_sizeì˜ 16%)\n",
    "    # - ì„¹ì…˜ ê²½ê³„ì—ì„œ ë¬¸ë§¥ì´ ëŠê¸°ëŠ” ê²ƒ ë°©ì§€\n",
    "    # - ê²€ìƒ‰ ì‹œ ê²½ê³„ ë¶€ê·¼ ì •ë³´ ë†“ì¹˜ì§€ ì•Šë„ë¡\n",
    "    # - ì¼ë°˜ì ìœ¼ë¡œ chunk_sizeì˜ 10-20% ê¶Œì¥\n",
    "    chunk_overlap=200,\n",
    "    \n",
    "    # ë¶„í•  ìš°ì„ ìˆœìœ„ (ìœ„ì—ì„œë¶€í„° ìˆœì„œëŒ€ë¡œ ì‹œë„)\n",
    "    separators=[\n",
    "        \"\\n## \",      # 1ìˆœìœ„: ë…¼ë¬¸ ì„¹ì…˜ í—¤ë” (## Abstract, ## Introduction)\n",
    "                      # Doclingì´ ì£¼ìš” ì„¹ì…˜ì„ 2ë ˆë²¨ í—¤ë”ë¡œ ë³€í™˜í•˜ë¯€ë¡œ\n",
    "                      # ê°€ì¥ í° ì˜ë¯¸ ë‹¨ìœ„ì¸ ì„¹ì…˜ì„ ë¨¼ì € ë³´ì¡´\n",
    "        \n",
    "        \"\\n### \",     # 2ìˆœìœ„: ì„œë¸Œì„¹ì…˜ (### 3.1 Dataset, ### 3.2 Model)\n",
    "                      # ì„¹ì…˜ì´ 1200ì ì´ˆê³¼ ì‹œ ì„œë¸Œì„¹ì…˜ ë‹¨ìœ„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë¶„í• \n",
    "        \n",
    "        \"\\n\\n\",       # 3ìˆœìœ„: ë¬¸ë‹¨ ê²½ê³„\n",
    "                      # ì„œë¸Œì„¹ì…˜ë„ ê¸¸ë©´ ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ë¶„í• \n",
    "                      # ë…¼ë¬¸ì€ ë¬¸ë‹¨ì´ ë…¼ë¦¬ì  ë‹¨ìœ„ì´ë¯€ë¡œ ì—¬ê¸°ì„œ ìë¥´ëŠ” ê²Œ ìì—°ìŠ¤ëŸ¬ì›€\n",
    "        \n",
    "        \"\\n\",         # 4ìˆœìœ„: ì¤„ë°”ê¿ˆ\n",
    "                      # ë¬¸ë‹¨ë„ ê¸¸ë©´ ì¤„ ë‹¨ìœ„ë¡œ\n",
    "                      # ìˆ˜ì‹, ë¦¬ìŠ¤íŠ¸, ì½”ë“œ ë¸”ë¡ ë“±ì€ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„ë¨\n",
    "        \n",
    "        \". \",         # 5ìˆœìœ„: ë¬¸ì¥ ë (ë§ˆì¹¨í‘œ + ê³µë°±)\n",
    "                      # ìµœì†Œí•œ ì™„ì „í•œ ë¬¸ì¥ì€ ìœ ì§€\n",
    "                      # ê³µë°±ê¹Œì§€ í¬í•¨í•´ì•¼ ë¬¸ì¥ ë ì •í™•íˆ ê°ì§€\n",
    "        \n",
    "        \" \",          # 6ìˆœìœ„: ë‹¨ì–´ ê²½ê³„ (ê³µë°±)\n",
    "                      # ë¬¸ì¥ë„ ì´ˆê³¼í•˜ë©´ ë‹¨ì–´ ë‹¨ìœ„ë¡œ\n",
    "                      # ìµœì†Œí•œ ë‹¨ì–´ëŠ” ìª¼ê°œì§€ì§€ ì•Šê²Œ\n",
    "        \n",
    "        \"\"            # 7ìˆœìœ„: ê°•ì œ ë¶„í•  (ë¬¸ì ë‹¨ìœ„)\n",
    "                      # ê¸´ URL, ì½”ë“œ, ìˆ˜ì‹ ë“± chunk_size ì´ˆê³¼ ì‹œ ë¬¸ìë¡œ ê°•ì œ ë¶„í• \n",
    "                      # ì—ëŸ¬ ë°©ì§€ìš© ìµœí›„ì˜ ì•ˆì „ì¥ì¹˜\n",
    "    ],\n",
    "    \n",
    "    # ì›ë³¸ ë¬¸ì„œì—ì„œì˜ ì‹œì‘ ìœ„ì¹˜ë¥¼ ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€\n",
    "    # - RAG ê²€ìƒ‰ í›„ ì¶œì²˜ ì¶”ì  ê°€ëŠ¥ (ëª‡ ë²ˆì§¸ ë¬¸ì/í˜ì´ì§€ì—ì„œ ì™”ëŠ”ì§€)\n",
    "    # - chunk.metadata['start_index']ë¡œ ì ‘ê·¼\n",
    "    # - ì‚¬ìš©ìì—ê²Œ \"ë…¼ë¬¸ 3í˜ì´ì§€ Introduction ì„¹ì…˜\" ê°™ì€ ì •ë³´ ì œê³µ ê°€ëŠ¥\n",
    "    add_start_index=True,\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec68256",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23324198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e6d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = BGEM3FlagModel(\"BAAI/bge-m3\")\n",
    "embedding_model.model.to(\"cuda\")\n",
    "embedding_model.model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c39d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(embedding_model.model.parameters()).device)\n",
    "print(next(embedding_model.model.parameters()).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f112d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [chunk.page_content for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea0d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4108d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = embedding_model.encode(\n",
    "    texts,\n",
    "    batch_size = 12,\n",
    "    max_length = 8192,\n",
    "    return_dense = True,\n",
    "    return_sparse = True,\n",
    "    return_colbert_vecs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0260909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['dense_vecs'][0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd60ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(outputs['lexical_weights'][0].items())[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a6d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch\n",
    "\n",
    "client = OpenSearch(\n",
    "    hosts=[{'host': 'localhost', 'port': 9200}],\n",
    "    http_compress=True,\n",
    "    use_ssl=False,\n",
    "    verify_certs=False\n",
    ")\n",
    "\n",
    "# ì—°ê²° í™•ì¸\n",
    "info = client.info()\n",
    "print(f\"OpenSearch version: {info['version']['number']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker_model_id = \"n5QFAJwBOacQ-9pbxjwZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e2e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"papers\"\n",
    "\n",
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"index\": {\n",
    "            # k-NN ê²€ìƒ‰ í™œì„±í™” (ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ ì‚¬ìš©)\n",
    "            \"knn\": True,\n",
    "            \n",
    "            # HNSW ê²€ìƒ‰ ì‹œ íƒìƒ‰í•  ì´ì›ƒ ë…¸ë“œ ìˆ˜\n",
    "            # ë†’ì„ìˆ˜ë¡ ì •í™•í•˜ì§€ë§Œ ëŠë¦¼ (ê¸°ë³¸ 100, ë²”ìœ„ 1~10000)\n",
    "            # ë…¼ë¬¸ ê²€ìƒ‰ì€ ì •í™•ë„ê°€ ì¤‘ìš”í•´ì„œ 100 ì„¤ì •\n",
    "            \"knn.algo_param.ef_search\": 100\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            # ë…¼ë¬¸ ë³¸ë¬¸/ì œëª© ë“± í…ìŠ¤íŠ¸ ì €ì¥\n",
    "            \"text\": {\n",
    "                \"type\": \"text\",  # ì „ë¬¸ ê²€ìƒ‰ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ í•„ë“œ\n",
    "                \"analyzer\": \"standard\"  # ì˜ì–´ ê¸°ë³¸ ë¶„ì„ê¸° (í† í°í™”, ì†Œë¬¸ìí™”)\n",
    "            },\n",
    "            \n",
    "            # ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° (ì €ì, ë‚ ì§œ, ì¶œì²˜ ë“±)\n",
    "            \"metadata\": {\n",
    "                \"type\": \"object\",  # JSON ê°ì²´ ì €ì¥\n",
    "                \"enabled\": True  # ì¸ë±ì‹± í™œì„±í™” (ê²€ìƒ‰/í•„í„°ë§ ê°€ëŠ¥)\n",
    "            },\n",
    "            \n",
    "            # BGE-M3 dense vector (ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰)\n",
    "            \"dense_vector\": {\n",
    "                \"type\": \"knn_vector\",  # ë²¡í„° ê²€ìƒ‰ìš© í•„ë“œ\n",
    "                \"dimension\": 1024,  # BGE-M3 ì¶œë ¥ ì°¨ì›\n",
    "                \n",
    "                \"method\": {\n",
    "                    # HNSW: ê·¼ì‚¬ ìµœê·¼ì ‘ ì´ì›ƒ ì•Œê³ ë¦¬ì¦˜ (ë¹ ë¥¸ ë²¡í„° ê²€ìƒ‰)\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \n",
    "                    # cosinesimil: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ë°©í–¥ ê¸°ë°˜ ìœ ì‚¬ë„)\n",
    "                    # ë…¼ë¬¸ ê²€ìƒ‰ì€ ì˜ë¯¸ ìœ ì‚¬ë„ê°€ ì¤‘ìš”í•´ì„œ cosine ì„ íƒ\n",
    "                    # ëŒ€ì•ˆ: l2(ìœ í´ë¦¬ë“œ), innerproduct(ë‚´ì )\n",
    "                    \"space_type\": \"cosinesimil\",\n",
    "                    \n",
    "                    # faiss: Metaì˜ ë²¡í„° ê²€ìƒ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ë¹ ë¥´ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
    "                    # ëŒ€ì•ˆ: lucene(ì‘ì€ ë°ì´í„°), nmslib(êµ¬ì‹)\n",
    "                    \"engine\": \"faiss\",\n",
    "                    \n",
    "                    \"parameters\": {\n",
    "                        # ef_construction: ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œ íƒìƒ‰ ë²”ìœ„\n",
    "                        # ë†’ì„ìˆ˜ë¡ ì •í™•í•œ ê·¸ë˜í”„ êµ¬ì¶•, ëŠë¦° ì¸ë±ì‹± (ê¸°ë³¸ 100)\n",
    "                        # 128: ë…¼ë¬¸ì²˜ëŸ¼ ê³ í’ˆì§ˆ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš°\n",
    "                        \"ef_construction\": 128,\n",
    "                        \n",
    "                        # m: ê° ë…¸ë“œê°€ ì—°ê²°í•  ì´ì›ƒ ìˆ˜\n",
    "                        # ë†’ì„ìˆ˜ë¡ ì •í™•í•˜ì§€ë§Œ ë©”ëª¨ë¦¬/ì†ë„ trade-off (ê¸°ë³¸ 16)\n",
    "                        # 16: ê· í˜•ì¡íŒ ì„¤ì • (ë²”ìœ„ 2~100)\n",
    "                        \"m\": 16\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \n",
    "            # BGE-M3 sparse vector (í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰)\n",
    "            \"sparse_vector\": {\n",
    "                # rank_features: í† í°ë³„ ê°€ì¤‘ì¹˜ ì €ì¥ (BM25ì™€ ìœ ì‚¬)\n",
    "                # {\"machine\": 0.8, \"learning\": 0.6, ...} í˜•íƒœ\n",
    "                # denseì™€ ê²°í•©í•´ì„œ hybrid search êµ¬í˜„\n",
    "                \"type\": \"rank_features\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e598408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¸ë±ìŠ¤ ì¡´ì¬ í™•ì¸ ë° ìƒì„±\n",
    "if not client.indices.exists(index=index_name):  # index= í‚¤ì›Œë“œ í•„ìˆ˜\n",
    "    client.indices.create(index=index_name, body=index_body)\n",
    "    print(f\"Index '{index_name}' created\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb0660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import helpers\n",
    "from tqdm import tqdm\n",
    "\n",
    "# bulk ìƒ‰ì¸ìš© ì•¡ì…˜ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "actions = []\n",
    "for i, chunk in enumerate(tqdm(chunks, desc=\"Indexing documents\")):\n",
    "    action = {\n",
    "        # ì¸ë±ìŠ¤ ì´ë¦„ ì§€ì •\n",
    "        \"_index\": index_name,\n",
    "        \n",
    "        # ë¬¸ì„œ ID (ë¬¸ìì—´ ê¶Œì¥)\n",
    "        \"_id\": str(i),\n",
    "        \n",
    "        # ë¬¸ì„œ ë‚´ìš© (_body ì•„ë‹˜!)\n",
    "        \"_source\": {\n",
    "            \"text\": chunk.page_content,\n",
    "            \"metadata\": chunk.metadata,\n",
    "            \n",
    "            # BGE-M3 dense vector (ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰)\n",
    "            # .tolist(): numpy array â†’ Python list ë³€í™˜ (JSON ì§ë ¬í™”)\n",
    "            \"dense_vector\": outputs['dense_vecs'][i].tolist(),\n",
    "            \n",
    "            # BGE-M3 sparse vector (í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰)\n",
    "            # rank_features íƒ€ì…ì€ {\"token\": weight, ...} dict í˜•íƒœ í•„ìš”\n",
    "            \"sparse_vector\": outputs['lexical_weights'][i]\n",
    "        }\n",
    "    }\n",
    "    actions.append(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad4d811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers.bulkë¡œ ëŒ€ëŸ‰ ìƒ‰ì¸\n",
    "success, failed = helpers.bulk(\n",
    "    client,  # OpenSearch í´ë¼ì´ì–¸íŠ¸\n",
    "    actions,  # ìƒ‰ì¸í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "    \n",
    "    # í•œ ë²ˆì— ë³´ë‚¼ ë¬¸ì„œ ìˆ˜ (ë©”ëª¨ë¦¬/ì„±ëŠ¥ ê· í˜•)\n",
    "    chunk_size=500,\n",
    "    \n",
    "    # ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ)\n",
    "    request_timeout=60,\n",
    "    \n",
    "    # ì—ëŸ¬ ë°œìƒ ì‹œ ì¤‘ë‹¨í•˜ì§€ ì•Šê³  ê³„ì† ì§„í–‰\n",
    "    raise_on_error=False\n",
    ")\n",
    "\n",
    "print(f\"Successfully indexed {success} documents, failed to index {failed} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b0dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Pipeline ìƒì„± (RRF ë°©ì‹)\n",
    "# ì¶œì²˜: https://opensearch.org/docs/latest/search-plugins/search-pipelines/score-ranker-processor/\n",
    "response = client.transport.perform_request(\n",
    "    'PUT',\n",
    "    '/_search/pipeline/hybrid_rrf_rerank',\n",
    "    body={\n",
    "        \"description\": \"Hybrid search with RRF and Cross-Encoder Reranking\",\n",
    "\n",
    "        # ===== 1ë‹¨ê³„: RRF (Reciprocal Rank Fusion) =====\n",
    "        # Dense/Sparse ê²°ê³¼ë¥¼ ìˆœìœ„ ê¸°ë°˜ìœ¼ë¡œ ë³‘í•©\n",
    "        \"phase_results_processors\": [\n",
    "            {\n",
    "                \"score-ranker-processor\": {\n",
    "                    \"combination\": {\n",
    "                        # RRF: ìˆœìœ„ ê¸°ë°˜ ë³‘í•© (ì ìˆ˜ ìŠ¤ì¼€ì¼ ë¬´ê´€)\n",
    "                        \"technique\": \"rrf\",\n",
    "\n",
    "                        # rank_constant: RRF ê³µì‹ì˜ k ê°’ (ê¸°ë³¸ 60)\n",
    "                        # ê³µì‹: score = 1 / (k + rank)\n",
    "                        \"rank_constant\": 60,\n",
    "\n",
    "                        # weights: [dense, sparse] ê°€ì¤‘ì¹˜\n",
    "                        \"parameters\": {\n",
    "                            \"weights\": [0.5, 0.5]  # ê· í˜• ì„¤ì •\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "\n",
    "        # ===== 2ë‹¨ê³„: Cross-Encoder Reranking =====\n",
    "        # RRF ê²°ê³¼ë¥¼ ML ëª¨ë¸ë¡œ ì •ë°€ ì¬í‰ê°€\n",
    "        \"response_processors\": [\n",
    "            {\n",
    "                \"rerank\": {\n",
    "                    \"ml_opensearch\": {\n",
    "                        \"model_id\": reranker_model_id  # ë“±ë¡í•œ ëª¨ë¸ ID\n",
    "                    },\n",
    "                    \"context\": {\n",
    "                        \"document_fields\": [\"text\"]  # ë¶„ì„ ëŒ€ìƒ í•„ë“œ\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"âœ… Search Pipeline 'hybrid_rrf_rerank' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38710500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Pipeline ì¡°íšŒ: ìƒì„±ëœ Pipeline ì„¤ì • í™•ì¸\n",
    "\n",
    "# HTTP GET ìš”ì²­ìœ¼ë¡œ íŠ¹ì • Pipelineì˜ ì„¤ì •ì„ ê°€ì ¸ì˜´\n",
    "pipeline = client.transport.perform_request(\n",
    "    'GET',\n",
    "    '/_search/pipeline/hybrid_rrf_rerank'  # ìƒì„±í•œ íŒŒì´í”„ë¼ì¸ ì´ë¦„\n",
    ")\n",
    "\n",
    "# ë°˜í™˜ê°’ ì¶œë ¥\n",
    "# - Pipelineì´ ì¡´ì¬í•˜ë©´: ì„¤ì • ë‚´ìš© (dict í˜•íƒœ)\n",
    "# - Pipelineì´ ì—†ìœ¼ë©´: 404 ì—ëŸ¬ ë°œìƒ\n",
    "print(pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Hybrid Search í•¨ìˆ˜: Dense + Sparse + Reranking\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # ============================================\n",
    "    # 1. ì¿¼ë¦¬ ì¸ì½”ë”© (BGE-M3)\n",
    "    # ============================================\n",
    "    query_output = embedding_model.encode(\n",
    "        [query],\n",
    "        return_dense=True,   # 1024ì°¨ì› ë²¡í„°\n",
    "        return_sparse=True   # ë‹¨ì–´:ê°€ì¤‘ì¹˜ ë”•ì…”ë„ˆë¦¬\n",
    "    )\n",
    "\n",
    "    # ============================================\n",
    "    # 2. Hybrid Search ì¿¼ë¦¬ êµ¬ì„±\n",
    "    # ============================================\n",
    "    search_body = {\n",
    "        \"size\": top_k * 10,  # Rerankerìš©ìœ¼ë¡œ ë” ë§ì´ ê°€ì ¸ì˜¤ê¸°\n",
    "        \"_source\": [\"text\", \"metadata\"],  # ë²¡í„° í•„ë“œ ì œì™¸\n",
    "\n",
    "        \"query\": {\n",
    "            \"hybrid\": {\n",
    "                \"queries\": [\n",
    "                    # Dense ê²€ìƒ‰ (ì˜ë¯¸ ê¸°ë°˜)\n",
    "                    {\n",
    "                        \"knn\": {\n",
    "                            \"dense_vector\": {\n",
    "                                \"vector\": query_output['dense_vecs'][0].tolist(),\n",
    "                                \"k\": top_k * 10\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "\n",
    "                    # Sparse ê²€ìƒ‰ (í‚¤ì›Œë“œ ê¸°ë°˜)\n",
    "                    {\n",
    "                        \"bool\": {\n",
    "                            \"should\": [\n",
    "                                {\n",
    "                                    \"rank_feature\": {\n",
    "                                        \"field\": f\"sparse_vector.{word}\",\n",
    "                                        \"boost\": score\n",
    "                                    }\n",
    "                                }\n",
    "                                for word, score in query_output['lexical_weights'][0].items()\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "\n",
    "        # Rerank Extension (Rerankerì— ì¿¼ë¦¬ ì „ë‹¬)\n",
    "        \"ext\": {\n",
    "            \"rerank\": {\n",
    "                \"query_context\": {\n",
    "                    \"query_text\": query  # Cross-Encoderê°€ ì‚¬ìš©\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # ============================================\n",
    "    # 3. ê²€ìƒ‰ ì‹¤í–‰ (Search Pipeline ì ìš©)\n",
    "    # ============================================\n",
    "    response = client.search(\n",
    "        index=index_name,\n",
    "        body=search_body,\n",
    "        params={\"search_pipeline\": \"hybrid_rrf_rerank\"}\n",
    "    )\n",
    "\n",
    "    # ============================================\n",
    "    # 4. ê²°ê³¼ íŒŒì‹± (ìƒìœ„ top_kê°œë§Œ)\n",
    "    # ============================================\n",
    "    results = []\n",
    "    for hit in response[\"hits\"][\"hits\"][:top_k]:\n",
    "        results.append({\n",
    "            \"text\": hit[\"_source\"][\"text\"],\n",
    "            \"metadata\": hit[\"_source\"][\"metadata\"],\n",
    "            \"score\": hit[\"_score\"]  # RRF + Reranker ìµœì¢… ì ìˆ˜\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26058e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Hybrid Search ì‹¤í–‰ ì˜ˆì‹œ\n",
    "# ============================================\n",
    "\n",
    "query = \"ReAct vs Chain-of-Thought prompting\"\n",
    "results = search_papers(query, top_k=3)\n",
    "\n",
    "print(f\"\\nğŸ” ê²€ìƒ‰ì–´: '{query}'\")\n",
    "print(f\"ğŸ“Š ê²°ê³¼: {len(results)}ê°œ\\n\")\n",
    "\n",
    "# ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ì²˜ë¦¬\n",
    "if not results:\n",
    "    print(\"âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"ğŸ“„ ê²°ê³¼ {i} | ì ìˆ˜: {result['score']:.4f}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ (ì²˜ìŒ 300ìë§Œ í‘œì‹œ)\n",
    "        text = result['text']\n",
    "        display_text = text[:300] + \"...\" if len(text) > 300 else text\n",
    "        print(f\"í…ìŠ¤íŠ¸:\\n{display_text}\")\n",
    "\n",
    "        # ë©”íƒ€ë°ì´í„° ì¶œë ¥\n",
    "        print(f\"\\në©”íƒ€ë°ì´í„°:\")\n",
    "        metadata = result.get('metadata', {})\n",
    "        if metadata:\n",
    "            for key, value in metadata.items():\n",
    "                print(f\"  - {key}: {value}\")\n",
    "        else:\n",
    "            print(\"  (ë©”íƒ€ë°ì´í„° ì—†ìŒ)\")\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de57a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaperGraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
